# Rule34 爬虫和批量上传使用说明

## 概述

这个解决方案包含两个部分：
1. **爬虫脚本** (`rule34-scraper.py`) - 爬取Rule34图片和完整标签信息
2. **批量上传工具** (`batch-upload-tool.html`) - 将爬取的图片批量上传到Supabase

## 第一步：使用爬虫脚本

### 安装依赖

```bash
pip install requests
```

### 运行爬虫

```bash
python rule34-scraper.py
```

### 爬虫功能

1. **自动获取标签类型**
   - 艺术家标签 (artist)
   - 角色标签 (character)
   - 版权/作品标签 (copyright)
   - 一般标签 (general)

2. **输出文件**
   - `rule34_downloads/images/` - 图片文件
   - `rule34_downloads/metadata.json` - 元数据文件

### 元数据格式示例

```json
[
  {
    "id": "12345",
    "filename": "12345.jpg",
    "file_path": "images/12345.jpg",
    "width": "1920",
    "height": "1080",
    "tags": {
      "all": ["tag1", "tag2", "tag3"],
      "artist": ["artist_name"],
      "character": ["character_name"],
      "copyright": ["series_name"],
      "general": ["other", "tags"]
    },
    "category": "anime",
    "supabase_tags": [
      "artist:artist_name",
      "character:character_name",
      "copyright:series_name",
      "tag1",
      "tag2"
    ]
  }
]
```

### 自定义爬取参数

在 `rule34-scraper.py` 的 `main()` 函数中修改：

```python
# 搜索特定标签
search_tags = "character:hatsune_miku"  # 搜索初音未来
# 或
search_tags = "artist:some_artist"      # 搜索特定艺术家
# 或
search_tags = "score:>100 rating:safe"  # 组合搜索

limit = 50   # 每页数量 (最大1000)
page = 0     # 页码 (从0开始)
```

### 常用搜索语法

- `score:>100` - 评分大于100
- `rating:safe` - 安全内容
- `rating:questionable` - 可疑内容
- `rating:explicit` - 成人内容
- `width:>1920` - 宽度大于1920
- `height:>1080` - 高度大于1080
- 多个标签用空格分隔表示AND关系

## 第二步：批量上传到Supabase

### 1. 打开批量上传工具

在浏览器中打开 `batch-upload-tool.html`

### 2. 连接Supabase

输入你的Supabase连接信息：
- URL: `https://你的项目.supabase.co`
- Anon Key: `你的匿名密钥`

点击"测试连接"确认连接成功。

### 3. 导入数据

1. **选择metadata.json文件**
   - 点击"选择 metadata.json 文件"
   - 选择爬虫生成的 `rule34_downloads/metadata.json`

2. **选择图片文件夹**
   - 点击"选择图片文件夹"
   - 选择 `rule34_downloads/images` 文件夹

### 4. 开始上传

1. 选择默认分类（如果爬虫没有正确判断分类）
2. 点击"开始批量上传"
3. 工具会逐个上传图片并显示进度

### 上传特性

- **断点续传** - 可以暂停和继续上传
- **错误处理** - 失败的文件会标记并继续下一个
- **进度显示** - 实时显示上传进度
- **标签可视化** - 显示艺术家、角色、版权标签

## 第三步：使用现有的上传工具

如果你更喜欢使用 `upload-helper-advanced.html`：

1. 将爬虫下载的图片手动选择
2. 使用元数据中的标签信息填写标签
3. 批量上传

### 快速导入标签的技巧

在控制台运行以下代码可以快速导入标签：

```javascript
// 读取metadata.json内容后
const metadata = [...]; // 粘贴metadata.json内容

// 为每个文件设置标签
metadata.forEach((item, index) => {
    console.log(`文件 ${item.filename}:`);
    console.log(`标签: ${item.supabase_tags.join(', ')}`);
});
```

## 高级用法

### 批量爬取多个页面

修改爬虫脚本添加循环：

```python
# 爬取前10页
for page in range(10):
    posts = scraper.get_posts(search_tags, limit=100, page=page)
    if not posts:
        break
    metadata.extend(scraper.process_posts(posts))
```

### 过滤特定类型的标签

在爬虫中自定义标签处理：

```python
def generate_supabase_tags(self, categorized_tags):
    tags = []
    
    # 只保留重要的艺术家和角色标签
    for artist in categorized_tags['artist'][:2]:  # 最多2个艺术家
        tags.append(f"artist:{artist}")
    
    for character in categorized_tags['character'][:5]:  # 最多5个角色
        tags.append(f"character:{character}")
    
    # 添加精选的一般标签
    important_tags = ['solo', 'multiple_girls', 'highres', 'absurdres']
    for tag in categorized_tags['general']:
        if tag in important_tags:
            tags.append(tag)
    
    return tags
```

## 注意事项

1. **请求频率** - 爬虫已设置延迟，避免请求过快
2. **存储限制** - 注意Supabase的存储空间限制
3. **内容过滤** - 使用rating参数过滤内容类型
4. **标签数量** - 避免每个图片标签过多（建议不超过20个）

## 常见问题

### Q: 爬虫提示"获取标签信息失败"
A: 这是正常的，某些标签可能没有详细信息，会被归类为general标签。

### Q: 上传时提示"文件已存在"
A: Supabase不允许重复文件名，可以在文件名中加入时间戳。

### Q: 如何只爬取特定艺术家的作品？
A: 使用 `search_tags = "artist:艺术家名称"` 进行搜索。

### Q: 批量上传工具找不到文件？
A: 确保选择的是包含图片的文件夹，不是单个文件。 