#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Rule34 å›¾ç‰‡çˆ¬è™«è„šæœ¬
åŠŸèƒ½ï¼šçˆ¬å–å›¾ç‰‡åŠå…¶å®Œæ•´æ ‡ç­¾ä¿¡æ¯ï¼ˆè‰ºæœ¯å®¶ã€è§’è‰²ã€ç‰ˆæƒç­‰ï¼‰
è¾“å‡ºï¼šå›¾ç‰‡æ–‡ä»¶ + JSONå…ƒæ•°æ®æ–‡ä»¶
"""

import requests
import json
import os
import time
from urllib.parse import urlparse, parse_qs
import xml.etree.ElementTree as ET
from pathlib import Path

class Rule34Scraper:
    def __init__(self, output_dir="rule34_downloads"):
        self.base_url = "https://api.rule34.xxx/index.php"
        self.output_dir = output_dir
        self.metadata_file = os.path.join(output_dir, "metadata.json")
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, "images"), exist_ok=True)
        
        # åŠ è½½å·²å­˜åœ¨çš„å…ƒæ•°æ®
        self.existing_metadata = self.load_existing_metadata()
        self.existing_ids = {item['id'] for item in self.existing_metadata}
        
        # æ ‡ç­¾åˆ†ç±»
        self.tag_categories = {
            'artist': [],      # è‰ºæœ¯å®¶
            'character': [],   # è§’è‰²
            'copyright': [],   # ç‰ˆæƒ/ä½œå“
            'general': []      # ä¸€èˆ¬æ ‡ç­¾
        }
    
    def load_existing_metadata(self):
        """åŠ è½½å·²å­˜åœ¨çš„å…ƒæ•°æ®"""
        if os.path.exists(self.metadata_file):
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return []
        return []
    
    def get_posts(self, tags="", limit=100, page=0):
        """è·å–å¸–å­åˆ—è¡¨"""
        params = {
            'page': 'dapi',
            's': 'post',
            'q': 'index',
            'tags': tags,
            'limit': limit,
            'pid': page
        }
        
        try:
            response = self.session.get(self.base_url, params=params)
            response.raise_for_status()
            
            # è§£æXMLå“åº”
            root = ET.fromstring(response.content)
            posts = []
            
            for post in root.findall('.//post'):
                post_data = {
                    'id': post.get('id'),
                    'file_url': post.get('file_url'),
                    'preview_url': post.get('preview_url'),
                    'tags': post.get('tags', '').split(),
                    'score': post.get('score'),
                    'rating': post.get('rating'),
                    'width': post.get('width'),
                    'height': post.get('height'),
                    'created_at': post.get('created_at'),
                    'md5': post.get('md5')
                }
                posts.append(post_data)
            
            return posts
            
        except Exception as e:
            print(f"è·å–å¸–å­å¤±è´¥: {e}")
            return []
    
    def get_tag_info(self, tag_name):
        """è·å–æ ‡ç­¾çš„è¯¦ç»†ä¿¡æ¯ï¼ˆç±»å‹ï¼šè‰ºæœ¯å®¶/è§’è‰²/ç‰ˆæƒç­‰ï¼‰"""
        params = {
            'page': 'dapi',
            's': 'tag',
            'q': 'index',
            'name': tag_name
        }
        
        try:
            response = self.session.get(self.base_url, params=params)
            response.raise_for_status()
            
            root = ET.fromstring(response.content)
            tag = root.find('.//tag')
            
            if tag is not None:
                return {
                    'name': tag.get('name'),
                    'type': int(tag.get('type', 0)),  # 0=general, 1=artist, 3=copyright, 4=character
                    'count': int(tag.get('count', 0))
                }
            
        except Exception as e:
            print(f"è·å–æ ‡ç­¾ä¿¡æ¯å¤±è´¥ {tag_name}: {e}")
        
        return None
    
    def categorize_tags(self, tags):
        """å°†æ ‡ç­¾åˆ†ç±»ä¸ºè‰ºæœ¯å®¶ã€è§’è‰²ã€ç‰ˆæƒç­‰"""
        categorized = {
            'artist': [],
            'character': [],
            'copyright': [],
            'general': []
        }
        
        for tag in tags:
            tag_info = self.get_tag_info(tag)
            if tag_info:
                tag_type = tag_info['type']
                if tag_type == 1:
                    categorized['artist'].append(tag)
                elif tag_type == 4:
                    categorized['character'].append(tag)
                elif tag_type == 3:
                    categorized['copyright'].append(tag)
                else:
                    categorized['general'].append(tag)
            else:
                categorized['general'].append(tag)
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.1)
        
        return categorized
    
    def download_image(self, url, filename):
        """ä¸‹è½½å›¾ç‰‡"""
        filepath = os.path.join(self.output_dir, "images", filename)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(filepath):
            print(f"  â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {filename}")
            return True
        
        try:
            response = self.session.get(url, stream=True)
            response.raise_for_status()
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            print(f"  âœ… ä¸‹è½½å®Œæˆ: {filename}")
            return True
        except Exception as e:
            print(f"  âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥ {url}: {e}")
            return False
    
    def process_posts(self, posts):
        """å¤„ç†å¸–å­åˆ—è¡¨"""
        new_metadata = []
        skipped_count = 0
        
        for i, post in enumerate(posts):
            print(f"\nå¤„ç†å¸–å­ {i+1}/{len(posts)}: ID {post['id']}")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»çˆ¬å–è¿‡
            if post['id'] in self.existing_ids:
                print(f"  â­ï¸  å·²å­˜åœ¨ï¼Œè·³è¿‡: ID {post['id']}")
                skipped_count += 1
                continue
            
            # è·å–æ–‡ä»¶æ‰©å±•å
            file_ext = os.path.splitext(urlparse(post['file_url']).path)[1]
            filename = f"{post['id']}{file_ext}"
            
            # ä¸‹è½½å›¾ç‰‡
            if self.download_image(post['file_url'], filename):
                # åˆ†ç±»æ ‡ç­¾
                print("  ğŸ·ï¸  åˆ†ææ ‡ç­¾ç±»å‹...")
                categorized_tags = self.categorize_tags(post['tags'])
                
                # åˆ›å»ºå…ƒæ•°æ®
                meta = {
                    'id': post['id'],
                    'filename': filename,
                    'file_path': f"images/{filename}",
                    'width': post['width'],
                    'height': post['height'],
                    'rating': post['rating'],
                    'score': post['score'],
                    'created_at': post['created_at'],
                    'tags': {
                        'all': post['tags'],
                        'artist': categorized_tags['artist'],
                        'character': categorized_tags['character'],
                        'copyright': categorized_tags['copyright'],
                        'general': categorized_tags['general']
                    },
                    'category': self.determine_category(categorized_tags),
                    'supabase_tags': self.generate_supabase_tags(categorized_tags)
                }
                
                new_metadata.append(meta)
                self.existing_ids.add(post['id'])  # æ·»åŠ åˆ°å·²å­˜åœ¨åˆ—è¡¨
                
                print(f"  ğŸ“Š å®Œæˆï¼è‰ºæœ¯å®¶: {len(categorized_tags['artist'])}, "
                      f"è§’è‰²: {len(categorized_tags['character'])}, "
                      f"ç‰ˆæƒ: {len(categorized_tags['copyright'])}, "
                      f"ä¸€èˆ¬: {len(categorized_tags['general'])}")
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(1)
        
        # åˆå¹¶æ–°æ—§å…ƒæ•°æ®å¹¶ä¿å­˜
        all_metadata = self.existing_metadata + new_metadata
        self.save_metadata(all_metadata)
        
        print(f"\nğŸ“ˆ å¤„ç†å®Œæˆç»Ÿè®¡:")
        print(f"  ğŸ“¥ æ–°å¢: {len(new_metadata)} ä¸ª")
        print(f"  â­ï¸  è·³è¿‡: {skipped_count} ä¸ª")
        print(f"  ğŸ“š æ€»è®¡: {len(all_metadata)} ä¸ª")
        
        return new_metadata
    
    def determine_category(self, categorized_tags):
        """æ ¹æ®æ ‡ç­¾åˆ¤æ–­åˆ†ç±»"""
        # å¯ä»¥æ ¹æ®æ ‡ç­¾å†…å®¹åˆ¤æ–­åˆ†ç±»
        # è¿™é‡Œæ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹
        if any('anime' in tag for tag in categorized_tags['general']):
            return 'anime'
        elif any('furry' in tag for tag in categorized_tags['general']):
            return 'furry'
        elif any('3d' in tag for tag in categorized_tags['general']):
            return '3d'
        else:
            return 'general'
    
    def generate_supabase_tags(self, categorized_tags):
        """ç”Ÿæˆé€‚åˆSupabaseçš„æ ‡ç­¾æ•°ç»„"""
        # åˆå¹¶æ‰€æœ‰æ ‡ç­¾ï¼Œä½†ä¼˜å…ˆæ˜¾ç¤ºé‡è¦æ ‡ç­¾
        tags = []
        
        # æŒ‰é‡è¦æ€§æ’åºï¼šè‰ºæœ¯å®¶ > è§’è‰² > ç‰ˆæƒ > ä¸€èˆ¬
        for artist in categorized_tags['artist']:
            tags.append(f"artist:{artist}")
        
        for character in categorized_tags['character']:
            tags.append(f"character:{character}")
        
        for copyright in categorized_tags['copyright']:
            tags.append(f"copyright:{copyright}")
        
        # åªæ·»åŠ éƒ¨åˆ†ä¸€èˆ¬æ ‡ç­¾ï¼ˆé¿å…å¤ªå¤šï¼‰
        for tag in categorized_tags['general'][:10]:
            tags.append(tag)
        
        return tags
    
    def save_metadata(self, metadata):
        """ä¿å­˜å…ƒæ•°æ®åˆ°JSONæ–‡ä»¶"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {self.metadata_file}")
    
    def generate_upload_script(self, metadata):
        """ç”Ÿæˆæ‰¹é‡ä¸Šä¼ è„šæœ¬"""
        upload_script = """
// æ‰¹é‡ä¸Šä¼ è„šæœ¬ - åœ¨ä¸Šä¼ å·¥å…·çš„æ§åˆ¶å°ä¸­è¿è¡Œ
// é¦–å…ˆç¡®ä¿å·²ç»è¿æ¥åˆ°Supabase

async function batchUpload() {
    const metadata = %s;
    
    for (const item of metadata) {
        console.log(`ä¸Šä¼ å›¾ç‰‡: ${item.filename}`);
        
        // è¿™é‡Œéœ€è¦å…ˆé€šè¿‡æ–‡ä»¶é€‰æ‹©å™¨é€‰æ‹©å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
        // æˆ–è€…ä½¿ç”¨å…¶ä»–æ–¹å¼è·å–æ–‡ä»¶å¯¹è±¡
        
        const uploadData = {
            file_path: `rule/${item.filename}`,
            category: item.category,
            tags: item.supabase_tags
        };
        
        console.log('å…ƒæ•°æ®:', uploadData);
        
        // å®é™…ä¸Šä¼ ä»£ç éœ€è¦é…åˆä¸Šä¼ å·¥å…·å®ç°
    }
}

// æ‰§è¡Œæ‰¹é‡ä¸Šä¼ 
// batchUpload();
""" % json.dumps(metadata, ensure_ascii=False)
        
        script_file = os.path.join(self.output_dir, "upload_script.js")
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(upload_script)
        print(f"ğŸ“œ ä¸Šä¼ è„šæœ¬å·²ç”Ÿæˆ: {script_file}")


def main():
    """ä¸»å‡½æ•°"""
    scraper = Rule34Scraper()
    
    # ç¤ºä¾‹ï¼šæœç´¢ç‰¹å®šæ ‡ç­¾
    search_tags = "score:>100"  # æœç´¢è¯„åˆ†å¤§äº100çš„å›¾ç‰‡
    limit = 10  # æ¯é¡µæ•°é‡
    page = 0    # é¡µç 
    
    print(f"ğŸš€ å¼€å§‹çˆ¬å– Rule34...")
    print(f"ğŸ” æœç´¢æ ‡ç­¾: {search_tags}")
    print(f"ğŸ“„ æ¯é¡µæ•°é‡: {limit}")
    print(f"ğŸ“š å·²æœ‰æ•°æ®: {len(scraper.existing_metadata)} ä¸ª")
    
    # è·å–å¸–å­
    posts = scraper.get_posts(search_tags, limit, page)
    print(f"ğŸ¯ æ‰¾åˆ° {len(posts)} ä¸ªå¸–å­")
    
    if posts:
        # å¤„ç†å¸–å­
        new_metadata = scraper.process_posts(posts)
        
        # ç”Ÿæˆä¸Šä¼ è„šæœ¬
        if new_metadata:
            scraper.generate_upload_script(new_metadata)
        
        print("\nğŸ‰ çˆ¬å–å®Œæˆï¼")
        print(f"ğŸ“ å›¾ç‰‡ä¿å­˜åœ¨: {scraper.output_dir}/images/")
        print(f"ğŸ“‹ å…ƒæ•°æ®ä¿å­˜åœ¨: {scraper.metadata_file}")
        print("\nğŸ”„ ä¸‹ä¸€æ­¥ï¼š")
        print("1. ä½¿ç”¨ metadata.json ä¸­çš„ä¿¡æ¯")
        print("2. é…åˆ batch-upload-tool.html æ‰¹é‡ä¸Šä¼ ")
        print("3. æˆ–ä½¿ç”¨ç”Ÿæˆçš„ upload_script.js")


if __name__ == "__main__":
    main() 